{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# GloVe"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "51f210d513bcecc5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Overview\n",
    "**Model Objective**: To generate vector representations of words that capture as much semantic and syntactic information as possible.\n",
    "**Input**: Corpus\n",
    "**Output**: Word vectors\n",
    "**Method Summary**:\n",
    "1. Construct a word co-occurrence matrix based on the corpus.\n",
    "2. Train word vectors using the co-occurrence matrix and the GloVe model.\n",
    "\n",
    "**Flow**:\n",
    "Start -> Compute co-occurrence matrix -> Train word vectors -> End"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "60282acf5c8ac598"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# 加载预训练的GloVe模型（需转换为Word2Vec格式）\n",
    "glove_path = \"glove.6B.100d.txt\"  # 下载地址：https://nlp.stanford.edu/projects/glove/\n",
    "model = KeyedVectors.load_word2vec_format(glove_path, binary=False, no_header=True)\n",
    "\n",
    "# 获取词向量\n",
    "vector = model[\"apple\"]\n",
    "similar_words = model.most_similar(\"king\", topn=5)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3c8e198b048f82ae"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## GloVe vs. Word2Vec: Comprehensive Comparison\n",
    "\n",
    "### Core Differences\n",
    "\n",
    "| Feature             | GloVe                           | Word2Vec                               |\n",
    "|---------------------|---------------------------------|----------------------------------------|\n",
    "| **Approach**        | Global co-occurrence statistics | Local context window prediction        |\n",
    "| **Training Method** | Matrix factorization            | Neural network (Skip-gram/CBOW)        |\n",
    "| **Data Usage**      | Entire corpus statistics        | Sliding window contexts                |\n",
    "| **Optimization**    | Least squares minimization      | Negative sampling/hierarchical softmax |\n",
    "\n",
    "\n",
    "### Performance Comparison\n",
    "\n",
    "| Task                | GloVe Advantage               | Word2Vec Advantage            |\n",
    "|---------------------|-------------------------------|-------------------------------|\n",
    "| Word Analogies      | Better (e.g., king → queen)   | Slightly worse                |\n",
    "| Training Speed      | Slower                        | Faster                        |\n",
    "| Memory Usage        | Higher (stores full matrix)   | Lower                         |\n",
    "| Rare Word Handling  | More stable                   | Less effective                |"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ffcaef62638d362d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
