{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Encoder-Decoder Model\n",
    "\n",
    "The **Encoder-Decoder framework** is a fundamental architecture in deep learning for tackling **sequence-to-sequence (Seq2Seq)** tasks. It is widely used in machine translation, text summarization, dialogue generation, speech recognition, and more. The core idea is to encode an input sequence into a fixed-length contextual representation and then decode it into a target sequence.\n",
    "\n",
    "1. **Core Components**\n",
    "**Encoder**\n",
    "Converts the input sequence (e.g., a sentence, audio signal) into a **context vector** that captures high-level semantic information.\n",
    "\n",
    "Common architectures: RNNs (LSTM, GRU), Transformer Encoder, or CNNs.\n",
    "Process: Processes the input step-by-step (e.g., word-by-word) and compresses it into a fixed-length vector (often the final hidden state).\n",
    "**Decoder**\n",
    "Generates the target sequence (e.g., translated text, summary) based on the context vector from the encoder.\n",
    "\n",
    "Common architectures: RNNs (LSTM) or Transformer Decoder.\n",
    "Generation: Operates in an **autoregressive** manner, producing outputs step-by-step while relying on previous predictions.\n",
    "\n",
    "2. **Workflow**\n",
    "**Encoding Phase**\n",
    "The encoder processes the input sequence sequentially, updating its hidden states.\n",
    "The final hidden state (or aggregated states) becomes the **context vector**.\n",
    "**Decoding Phase**\n",
    "The decoder initializes with the context vector and generates the target sequence.\n",
    "At each step, it produces an output token (e.g., a word) and updates its hidden state until an end-of-sequence token (e.g., <EOS>) is generated or a maximum length is reached.\n",
    "\n",
    "6. **Pros & Cons**\n",
    "**Pros**:\n",
    "* Versatile for diverse Seq2Seq tasks.\n",
    "* Attention and Transformer variants address long-sequence limitations.\n",
    "\n",
    "**Cons**:\n",
    "* Early RNN-based models suffered from vanishing gradients.\n",
    "* Generation errors (e.g., repetition) may require post-hoc optimization (e.g., beam search)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "28a687fd389aa27d"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 20000 samples in data/\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import os\n",
    "from string import ascii_lowercase\n",
    "\n",
    "def generate_word(min_len=3, max_len=12):\n",
    "    \"\"\"生成随机单词，包含重复字母\"\"\"\n",
    "    length = random.randint(min_len, max_len)\n",
    "    return ''.join(random.choices(ascii_lowercase, k=length))\n",
    "\n",
    "def generate_dataset(num_samples=1000, output_dir=\"data\"):\n",
    "    \"\"\"生成训练数据集\"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    seen = set()\n",
    "    source_path = os.path.join(output_dir, \"source_data.txt\")\n",
    "    target_path = os.path.join(output_dir, \"target_data.txt\")\n",
    "    \n",
    "    with open(source_path, 'w') as src_f, open(target_path, 'w') as tgt_f:\n",
    "        generated = 0\n",
    "        while generated < num_samples:\n",
    "            # 生成原始单词（可能包含重复字母）\n",
    "            word = generate_word()\n",
    "            \n",
    "            # 生成排序后的目标\n",
    "            sorted_word = ''.join(sorted(word))\n",
    "            \n",
    "            # 排除重复案例\n",
    "            if (word, sorted_word) not in seen:\n",
    "                seen.add((word, sorted_word))\n",
    "                src_f.write(f\"{word}\\n\")\n",
    "                tgt_f.write(f\"{sorted_word}\\n\")\n",
    "                generated += 1\n",
    "                \n",
    "                # 生成包含重复字母的变体\n",
    "                if random.random() < 0.3:\n",
    "                    dup_word = word + random.choice(word)\n",
    "                    dup_sorted = ''.join(sorted(dup_word))\n",
    "                    if (dup_word, dup_sorted) not in seen:\n",
    "                        seen.add((dup_word, dup_sorted))\n",
    "                        src_f.write(f\"{dup_word}\\n\")\n",
    "                        tgt_f.write(f\"{dup_sorted}\\n\")\n",
    "                        generated += 1\n",
    "\n",
    "    print(f\"Generated {generated * 2} samples in {output_dir}/\")\n",
    "\n",
    "# 使用示例（生成包含10,000个样本的数据集）\n",
    "generate_dataset(num_samples=10000, output_dir='data')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-07T06:05:24.739147Z",
     "start_time": "2025-04-07T06:05:24.704862Z"
    }
   },
   "id": "4864ae33349e6b78",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Train Loss: 2.913\n",
      "Epoch: 02 | Train Loss: 2.258\n",
      "Epoch: 03 | Train Loss: 1.964\n",
      "Epoch: 04 | Train Loss: 1.750\n",
      "Epoch: 05 | Train Loss: 1.573\n",
      "Epoch: 06 | Train Loss: 1.425\n",
      "Epoch: 07 | Train Loss: 1.308\n",
      "Epoch: 08 | Train Loss: 1.205\n",
      "Epoch: 09 | Train Loss: 1.114\n",
      "Epoch: 10 | Train Loss: 1.024\n",
      "Epoch: 11 | Train Loss: 0.943\n",
      "Epoch: 12 | Train Loss: 0.879\n",
      "Epoch: 13 | Train Loss: 0.811\n",
      "Epoch: 14 | Train Loss: 0.759\n",
      "Epoch: 15 | Train Loss: 0.706\n",
      "Epoch: 16 | Train Loss: 0.661\n",
      "Epoch: 17 | Train Loss: 0.620\n",
      "Epoch: 18 | Train Loss: 0.577\n",
      "Epoch: 19 | Train Loss: 0.535\n",
      "Epoch: 20 | Train Loss: 0.502\n",
      "Epoch: 21 | Train Loss: 0.474\n",
      "Epoch: 22 | Train Loss: 0.444\n",
      "Epoch: 23 | Train Loss: 0.414\n",
      "Epoch: 24 | Train Loss: 0.392\n",
      "Epoch: 25 | Train Loss: 0.369\n",
      "Epoch: 26 | Train Loss: 0.350\n",
      "Epoch: 27 | Train Loss: 0.334\n",
      "Epoch: 28 | Train Loss: 0.310\n",
      "Epoch: 29 | Train Loss: 0.293\n",
      "Epoch: 30 | Train Loss: 0.279\n",
      "Epoch: 31 | Train Loss: 0.266\n",
      "Epoch: 32 | Train Loss: 0.247\n",
      "Epoch: 33 | Train Loss: 0.239\n",
      "Epoch: 34 | Train Loss: 0.229\n",
      "Epoch: 35 | Train Loss: 0.214\n",
      "Epoch: 36 | Train Loss: 0.204\n",
      "Epoch: 37 | Train Loss: 0.195\n",
      "Epoch: 38 | Train Loss: 0.187\n",
      "Epoch: 39 | Train Loss: 0.178\n",
      "Epoch: 40 | Train Loss: 0.170\n",
      "Epoch: 41 | Train Loss: 0.165\n",
      "Epoch: 42 | Train Loss: 0.153\n",
      "Epoch: 43 | Train Loss: 0.150\n",
      "Epoch: 44 | Train Loss: 0.146\n",
      "Epoch: 45 | Train Loss: 0.137\n",
      "Epoch: 46 | Train Loss: 0.133\n",
      "Epoch: 47 | Train Loss: 0.125\n",
      "Epoch: 48 | Train Loss: 0.125\n",
      "Epoch: 49 | Train Loss: 0.117\n",
      "Epoch: 50 | Train Loss: 0.117\n",
      "Epoch: 51 | Train Loss: 0.112\n",
      "Epoch: 52 | Train Loss: 0.105\n",
      "Epoch: 53 | Train Loss: 0.102\n",
      "Epoch: 54 | Train Loss: 0.099\n",
      "Epoch: 55 | Train Loss: 0.094\n",
      "Epoch: 56 | Train Loss: 0.093\n",
      "Epoch: 57 | Train Loss: 0.090\n",
      "Epoch: 58 | Train Loss: 0.090\n",
      "Epoch: 59 | Train Loss: 0.085\n",
      "Epoch: 60 | Train Loss: 0.086\n",
      "Input: common => Prediction: mmnoo\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# 数据预处理\n",
    "def build_vocab(data):\n",
    "    special_tokens = ['<PAD>', '<UNK>', '<GO>', '<EOS>']\n",
    "    chars = set()\n",
    "    for line in data:\n",
    "        chars.update(line)\n",
    "    chars = sorted(list(chars))\n",
    "    vocab = special_tokens + chars\n",
    "    int2vocab = {i: c for i, c in enumerate(vocab)}\n",
    "    vocab2int = {c: i for i, c in int2vocab.items()}\n",
    "    return int2vocab, vocab2int\n",
    "\n",
    "def process_data(source_path, target_path):\n",
    "    with open(source_path, 'r', encoding='utf-8') as f:\n",
    "        source_data = f.read().split('\\n')\n",
    "    with open(target_path, 'r', encoding='utf-8') as f:\n",
    "        target_data = f.read().split('\\n')\n",
    "    \n",
    "    source_int2vocab, source_vocab2int = build_vocab(source_data)\n",
    "    target_int2vocab, target_vocab2int = build_vocab(target_data)\n",
    "    \n",
    "    # 转换序列并添加EOS\n",
    "    source_sequences = []\n",
    "    for line in source_data:\n",
    "        seq = [source_vocab2int.get(c, source_vocab2int['<UNK>']) for c in line]\n",
    "        source_sequences.append(seq)\n",
    "    \n",
    "    target_sequences = []\n",
    "    for line in target_data:\n",
    "        seq = [target_vocab2int.get(c, target_vocab2int['<UNK>']) for c in line]\n",
    "        seq.append(target_vocab2int['<EOS>'])\n",
    "        target_sequences.append(seq)\n",
    "    \n",
    "    return (source_int2vocab, source_vocab2int, \n",
    "            target_int2vocab, target_vocab2int, \n",
    "            source_sequences, target_sequences)\n",
    "\n",
    "# 数据集类\n",
    "class Seq2SeqDataset(Dataset):\n",
    "    def __init__(self, source, target):\n",
    "        self.source = source\n",
    "        self.target = target\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.source)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.source[idx], self.target[idx]\n",
    "\n",
    "# 数据预处理函数\n",
    "def collate_fn(batch, src_pad, trg_pad):\n",
    "    sources, targets = zip(*batch)  # sources: [src1, src2, ...] targets: [trg1, trg2, ...]\n",
    "    src_lens = [len(s) for s in sources]    \n",
    "    trg_lens = [len(t) for t in targets]\n",
    "    \n",
    "    # 按源序列长度排序\n",
    "    sorted_indices = sorted(range(len(src_lens)), key=lambda i: -src_lens[i])\n",
    "    sources = [sources[i] for i in sorted_indices]\n",
    "    targets = [targets[i] for i in sorted_indices]\n",
    "    src_lens = [src_lens[i] for i in sorted_indices]\n",
    "    trg_lens = [trg_lens[i] for i in sorted_indices]\n",
    "    \n",
    "    # 填充序列\n",
    "    max_src = max(src_lens)\n",
    "    max_trg = max(trg_lens)\n",
    "    \n",
    "    padded_sources = []\n",
    "    for s in sources:\n",
    "        padded = s + [src_pad] * (max_src - len(s))\n",
    "        padded_sources.append(padded)\n",
    "    \n",
    "    padded_targets = []\n",
    "    for t in targets:\n",
    "        padded = t + [trg_pad] * (max_trg - len(t))\n",
    "        padded_targets.append(padded)\n",
    "    \n",
    "    return (torch.LongTensor(padded_sources).t().contiguous(),\n",
    "            torch.LongTensor(padded_targets).t().contiguous(),\n",
    "            src_lens,\n",
    "            trg_lens)\n",
    "\n",
    "# 编码器\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim, padding_idx=0)\n",
    "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout=dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, src, src_lens):\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(embedded, src_lens)\n",
    "        outputs, (hidden, cell) = self.rnn(packed)\n",
    "        outputs, _ = nn.utils.rnn.pad_packed_sequence(outputs)\n",
    "        return hidden, cell\n",
    "\n",
    "# 解码器\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim, padding_idx=0)\n",
    "        self.rnn = nn.LSTM(emb_dim, hid_dim, n_layers, dropout=dropout)\n",
    "        self.fc = nn.Linear(hid_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, input, hidden, cell):\n",
    "        input = input.unsqueeze(0)\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
    "        prediction = self.fc(output.squeeze(0))\n",
    "        return prediction, hidden, cell\n",
    "\n",
    "# Seq2Seq模型\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        \n",
    "    def forward(self, src, trg, src_lens, teacher_forcing_ratio=0.5):\n",
    "        batch_size = trg.shape[1]\n",
    "        trg_len = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        \n",
    "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
    "        \n",
    "        hidden, cell = self.encoder(src, src_lens)\n",
    "        \n",
    "        input = trg[0,:]\n",
    "        for t in range(1, trg_len):\n",
    "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
    "            outputs[t] = output\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            top1 = output.argmax(1)\n",
    "            input = trg[t] if teacher_force else top1\n",
    "            \n",
    "        return outputs\n",
    "\n",
    "# 训练函数\n",
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for _, (src, trg, src_lens, trg_lens) in enumerate(iterator):\n",
    "        src, trg = src.to(device), trg.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, trg, src_lens)\n",
    "        output_dim = output.shape[-1]\n",
    "        output = output[1:].view(-1, output_dim)\n",
    "        trg = trg[1:].view(-1)\n",
    "        loss = criterion(output, trg)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    return epoch_loss / len(iterator)\n",
    "\n",
    "# 参数设置\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "BATCH_SIZE = 128\n",
    "ENC_EMB_DIM = 15\n",
    "DEC_EMB_DIM = 15\n",
    "HID_DIM = 50\n",
    "N_LAYERS = 2\n",
    "ENC_DROPOUT = 0.1\n",
    "DEC_DROPOUT = 0.1\n",
    "N_EPOCHS = 60\n",
    "CLIP = 5\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# 数据加载\n",
    "(source_int2vocab, source_vocab2int, \n",
    " target_int2vocab, target_vocab2int, \n",
    " source_sequences, target_sequences) = process_data('data/source_data.txt', 'data/target_data.txt')\n",
    "\n",
    "dataset = Seq2SeqDataset(source_sequences, target_sequences)\n",
    "data_loader = DataLoader(dataset, batch_size=BATCH_SIZE,\n",
    "                        collate_fn=lambda x: collate_fn(x,  # [(src1, trg1), (src2, trg2), ..]\n",
    "                                                       source_vocab2int['<PAD>'], \n",
    "                                                       target_vocab2int['<PAD>']))\n",
    "\n",
    "# 初始化模型\n",
    "enc = Encoder(len(source_vocab2int), ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
    "dec = Decoder(len(target_vocab2int), DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
    "model = Seq2Seq(enc, dec, device).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "\n",
    "# 训练循环\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_loss = train(model, data_loader, optimizer, criterion, CLIP)\n",
    "    print(f'Epoch: {epoch+1:02} | Train Loss: {train_loss:.3f}')\n",
    "\n",
    "# 预测函数\n",
    "def predict(model, src_sequence, src_vocab2int, trg_vocab2int, trg_int2vocab, max_len=20):\n",
    "    model.eval()\n",
    "    src = [src_vocab2int.get(c, src_vocab2int['<UNK>']) for c in src_sequence]\n",
    "    src_tensor = torch.LongTensor(src).unsqueeze(1).to(device)\n",
    "    src_len = [len(src)]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        hidden, cell = model.encoder(src_tensor, src_len)\n",
    "    \n",
    "    trg_indexes = [trg_vocab2int['<GO>']]\n",
    "    for _ in range(max_len):\n",
    "        trg_tensor = torch.LongTensor([trg_indexes[-1]]).to(device)\n",
    "        with torch.no_grad():\n",
    "            output, hidden, cell = model.decoder(trg_tensor, hidden, cell)\n",
    "        pred_token = output.argmax(1).item()\n",
    "        trg_indexes.append(pred_token)\n",
    "        if pred_token == trg_vocab2int['<EOS>']:\n",
    "            break\n",
    "    return ''.join([trg_int2vocab[i] for i in trg_indexes[1:-1]])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-07T06:09:25.790084Z",
     "start_time": "2025-04-07T06:07:01.438671Z"
    }
   },
   "id": "1d51eaa681853ed1",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: whoami => Prediction: himow\n"
     ]
    }
   ],
   "source": [
    "# 示例预测\n",
    "input_word = 'whoami'\n",
    "prediction = predict(model, input_word, source_vocab2int, target_vocab2int, target_int2vocab)\n",
    "print(f'Input: {input_word} => Prediction: {prediction}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-07T06:11:39.719118Z",
     "start_time": "2025-04-07T06:11:39.714812Z"
    }
   },
   "id": "806df96528c23a80",
   "execution_count": 16
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
